cd /c/Users/srika/devsecops/shellscript/Notes/Terraform_notes/
git add . ; git commit -m "terraform_start" ; git push origin main
 git log to know errors
cd /D/Terraform/terraform-repos/

							FINAL NOTES FOR TERRAFORM
							==========================

							  SES-29-c1
						   *****************
**Use Terraform for better  infra creation. Once servers are created by Terraform, then hand over them to Ansible, so here Ansible completes the configuration in the server**
--->  Terraform can manage or owner of the server infrastructure

Terraform -> IaaC ( Infrastructure as a code )

CM -> Configuration as a code

---> So why do we write code? bcz manual ga one server loki login  ayyi emi emi configuration and properties vunnnai chudandi ante chala kastum and time consumed, so adhe code laga rasukunte it will be easy to track everything in that server....

---> CRUD operations ni easy ga perform cheyachhu in code 
--> so code lo ithe eas ga CRUD operations cheyachuu
--> so finally infra kuda consistency laga vundali.
Inventory -> ikkada chuste manaki easy ga telustundhi  
Cost optimisation ---->
Time saving and no human errors
Dependency -> SG, EC2 and then R53 

Terraform, Pulumi, Cloudformation, etc..  all are the same, but based on the latest version we can use here

HCL -> HashiCorp Configuration Language .. terraform introduced this company

--> terraform anedhi server run cheyamu ( it doesn't work within server) 
--> terraform ni use chesi rasina code tho aws lo server ni create cheyachu that is infrasture so aws ni connect or access cheyanlante we need to install terraform in our windows

-> in terraform everything is key value based like key = somevalue.....
--> terraform always follow this syntax...as below
resource "type_of_resource" "name-of-resource"
 {
	
	key = value
	
}
---> provider.tf --- so here manam cheptunam dheniki connect avvali ani, its mandatory for terraform

---> Terraform commands will have been worked at .tf folder only
1. terraform init -> downloads the provider, intialise terraform
2. terraform plan -> It will give us a plan that what it is going to do
3. terraform apply -> creates the infra as given in the plan

terraform apply -auto-approve --> if u provide like these it doesn't ask any permission like yes so its automatically procced 

terraform destroy -auto-approve  It means all data will be destroyed, sg and instance all

-->Ingress ( Data in )means entrance, or the right to enter, or the act of entering

--> Egress (Data Out)
Definition: Data leaving a network or system (e.g., downloading from the cloud, sending emails).

OVER VIEW
=================================================================================

1. installed terraform, setup the env variable in system path
2. aws cli v2 install
3. aws configure

terraform init
terraform plan
terraform apply
terraform destroy

--> the syntax we called as HCL 
The HashiCorp Configuration Language (HCL) syntax is designed to be human-readable and machine-friendly, built primarily around arguments, blocks, and expressions. It is used in HashiCorp products like Terraform, Nomad, and Packer. 

resource "type_of_resource" "resource_name_our_wish" {
	key = "value"
}


		=====================================================================
							  SES-30-c2
						   *****************
git -> repository to store only code. here max 50 MB varaku store cheyali ani restrict chesaru
.gitignore means konni files ni ignore chei ani cheptundhi andhulo vunttai emi emi ignore cheyalo..

rm -rf .git
add .gitignore
git init
git branch -M main
git remote add origin <URL>
git add . ; git commit ; git push

$ git add . ; git commit -m "terraform_start" ; git push origin main -f  ( so here -f used to for force push ) 

variables
========= DRY ===
Syntax is
---------
variable "variable_name" {
	default = "value-of-variable"
}

ex:- var.ami_id and var.instance_type  like this u can refer in ec2.tf lo 

--> data types means int,string,boolean,number....float
preference topic
===========
1. command line variable values have first preference
syntax: terraform plan -var='instance_type=t2.micro'

2. terraform.tfvars
syntax:: terraform plan -var-file='my-vars.tfvars'   ---> another model ---> 

3. env variable TF_VAR_<variable_name>

synrtax::;  export TF_VAR_instance_type="t3.reddy"
unset TF_VAR_instance_type ----> ila ivvatum valla adhi remove avuthundi ---> default state ki vastundhi

4. default value so  emiana vundha ani..

So actually ga user ni adugutham value ni provide chayamani, vallaki teliyali ga
so manaki readability kosam manam type anedhi use chestam, like string or map or list or number ani...........

5. finally prompt  --> it means manam value ni enter cheyali 
conditions
==============
in terraform syntax is:
------------------------
expression ? "this will run if true" : "this will run if false"

EX : instance_type = var.environment == "dev" ? "t3.micro" : "t3.medium"

count based loop
================
count = length(var.instances) or else count = 10
count.index -> special variable --> terraform has given like this 
So basically index starts from 0 

so this called count based usually works with list items.....

-->if in case u wrote all tf files in single folder terraform will start the execution alphabetical order...abcde...
interpolation
============
concatenating variable and other content--> it means add 2 variables


OVER VIEW
=================================================================================

Variables:-
=============
variable "var_name" {
	default = "default_value"
}

--> SO inka varibales like as below laga kuda declare cheyachu

1. Through command line
2. terraform.tfvars
3. ENV variable TF_VAR_var_name
4. default value
5. prompt it means it is asking pls enter like that

var.var_name --> ila code lo variables ni declare cheyachu

"${var.var_name}" --> ila ekkuva vars ni declare cheyalante process like this

types of variables
================
number
string
list
map
bool

Condition:-
==============
expression ? "true" : "false"

loops
======
count based loop -> it is used to get list iteration, here aa process lo manaki count.index ani vastundi

count = number

count.index --> so ikkasa loop ayina everytime manaki ila oka special variables istundhi   ---------------> these all are learn by class 30 
==============
resource "aws_instance" "terraform" {} --> so ikkada ee block varaku output kavalante u need to ask like these ..so ala dhenikaina kuda we can get........

output "instances_output" 
{
#   value = aws_instance.terraform # so idhi ec2.tf lo name vuntthdi so akkada numchi tisukovali
# }
		=====================================================================
							  SES-31-c3
						   *****************
for loop --> we are using it, in set or map situation lo use chestam...
for_each = toset(["bucket-alpha", "bucket-beta", "bucket-gamma"])  --> so ikkada map ki matrame chestam, don't use it in at count 

list -> string values --> in this situation we need to use count-based
map -> key and values  --> in this situation we need to use for-loops

I want to iterate list through for_each then here u have to convert into toset
---> so map details levvu anukunte list deatails ni map loki convert cheyalante we need toset syntax appudu list nuchi map convert ayyi key = value avuthundhi

Syntax is: 
=========
for_each = toset(list) 
---> here list convert into set or map ---> after done iteration we will get each.value.... in this toset both are same like each.key or each.value

count -> list -> count.index
for_each -> map -> each.key and each.value


data sources
==============
---> in aws after created servers or instances, values ni query or pickup chesukovatame data sources...
---> sources means we can query the existing information in the provider using data sources.

Syntax is: 
=========
data "aws_ami" "joindevops" {  ---> "aws_ami" here edhi ithe query cheyalanukuntunaro aa name ivvali..  "joindevops" this name is our choice
	parameters to query
}

--> so here evaru ithe ami id create chesi push chestaro  Valle owner avutharu ---> very IMP topic projects lo baga use chestaru ......
---->So finally manual ga ayina or terraform tho ayina create chesina server lo numchi manam akkada vuna data ni qury cheyachu means bayatiki tisukoni save chesukovachhu

functions : it means take i/p and give o/p
============
EX 1
-----
> join("_",["Srikanth","Reddy","Erugula"])
"Srikanth_Reddy_Erugula"

EX 2 : give like this max(5, 12, 9)

merge function

--->merge({a="b", c="d"}, {e="f", c="z"})
          ({map1}       , { map2})
--> Finally map1 and map2 iste.. always map2 anedhi map1 vunna contenct replace cheyadaki chustadi..

result:-
=====
a = b
c = z
e = f

--->The Terraform merge function combines multiple maps or objects into a single map or object.
--> Finally map1 and map2 iste.. always map2 anedhi map1 vunna contenct replace cheyadaki chustadi..



state
=========
Terraform responsibility is whatever we give in .tf files, it should create those resources ->is called declarative way of creating infra( so here manam cheptunam naaku idhi kavali ani nuvvu ichina syntx follow avvuthu rasi istunam) 

--> A "declarative way" means describing what you want as a result, not how to get it

matching you declared infra with actual infra in AWS account

--> Terraform responsibility is   manam ichhina desired infra tho actual infra ni match cheyatum.... so then state file tho comparison chesukoni then will start re create if not present

What is terraform state
=====================
terraform state is used to match the desired infra with actual infra, when create read update and delete the infra terraform uses this state file to achieve the desired infra for comparison. It is like memory to terraform

---> terraform locks the state file when terraform is running......>it means terraform apply ni run chestunte, so there tfstate file ni terraform lock chestundi, evvaru kuda disturb cheyakunda.>   process anthe run tharvatha unlock chestundi..appudu manaki visible avuthundi..

--> so finaly state file anedhi terraform kosame vundi, adhe CRUD operation chesukoni adhe manage chesukunttadhi so terraform has full rights of state file..
--> state file terraform kasame pani chestundhi....

		=====================================================================
							  SES-32-c4
						   *****************
Remote state
==============
--> We should secure state file from accidental changes.  --> it means unfortunately keys press avavtum and delete avvatum with our interruption  .  
---> what is the solution while multiple persons are work chestunte ----> simple solu is centralised state or block or room

we must keep state file in remote location while working in collaboration environment for security and preventing duplicate resources and errors, when multiple members( team members) are working together

--> state file should be locked when terraform is doing something, so for that others can't apply the changes.

--> drive lo manam ela folder create chetamo ala aws lo s3 bucket create cheyali.. for starage purpose our state file....
--> here entire aws s3 bucket name should be unique ga vundali...

--> dsoaws-remote-state --> s3 bucket create chesam next aa file location or path access terraform ki ichhi state files ni akkada store chesuko ani cheppali...

Syntax
-======

backend "s3" { # backend ante remote store ani anukovali
    bucket = "dsoaws-remote-state"
    key    = "remote-state-demo" # so here keys must be not for the same for all, u have to set name as per the requirement like dev ithe dev name and prod ithe prod name 
    region = "us-east-1"
    use_lockfile = true
    encrypt = true --> it means unauthorised person file tisukuna no use bcz data has been encrypt....

---> these are available in provider.tf file 
--> if u a done any changes in provider.tf file then immediately give cmd like (terraform init -reconfigure )

locals
=======
--> so here variable.tf file access andhariki ivvakudadhu or else small company run chestunte vallu as per the budget vallu t3.micro ni use chestaru manam variable.tf file ki access iste  team vallu dhani change chesi use chesukuntaru so we aren't give access to them.. for that we need to create local.tf for restrict purpose..

--> local.tf introduced by  terraform so we can't do any changes.. inside file.

locals are like variables but it has many extra capabilities

1. variables can be overridden, locals can't be overridden ( re-write by someone)
2. we can use variables inside locals. but we can't use one variable in another variable

SYNTAX:
===========
variable "common_name" {
    default = "${var.project}-${var.environment}"
}
3. you can store expressions or functions inside locals block and reuse them whenever required

dynamic block ----> not much use in real time we need to know basic matter about that
==============
loops inside terraform
	count based
	for_each
	dynamic
SYNTAX:
===========
dynamic "setting" {
    for_each = var.settings
    content {
      namespace = setting.value["namespace"]
      name = setting.value["name"]
      value = setting.value["value"]
    }
  }

--> oka block multiple times repeated avuthunte we need to use dynamic......

Provisioners
============
usually terraform is creating instance, if we want to configure terraform is allowing to run few scripts
--> basically provisioning means it will change position to another position... 
We have to options like as below
1. local-exec ---> Simply terraform commands ekkada ithe vundho or run cheestunte  adi local
SYNTAX:
=======
provisioner "local-exec"{
      command = "echo ${self.private_ip} > inventory"
      #on_failure = continue  ---> it means continuing when we resources failed as well

    }
on_failure = continue  it is use like oka vela ip address inventory file lo rayalekapothe provisioner ila cheptundhi the above ec2 resource also failed ni.. so to overcome this issue u need to add on_fail ane option ni add cheste  then provision says like ec2 resources no fail......

 provisioner "local-exec"{
      command = "echo Instance is destroyed"
      when    = destroy   ---> it means destroy time lo kuda run avuthundhi or else creation time lo kuda run avuthundhi....
    }
--> Destroy ani ivvaka pothe adhi by default creation time anukoni manaki print avuthundhi....

2. remote-exec ---> so here local tho server or ec2 instance crate chesi serve loki login ayyi akkada some commands or actions perform excute chese dhani remote exce antam

ansible-playbook -i inventory playbook.yaml ----> ila ansible ki connect cheyachu for server configuration ki

OVER VIEW
=================================================================================

Terraform
===========
setup
variables
data types
conditions -> expression ? "true-value": "false-value"
loops
	count based -> list ki use chestam
	for each -> set/map ki use chestam
	dynamic block
functions -> in built functions

data sources -> query the existing info from provider
locals -> store expressions, functions. we can reuse them. cant override these values. we can variables inside locals
state -> matching desired infra with actual infra using state
remote state -> keep the state secure, for collaboration as well. locking it
provisioners -> when we create ec2 instances we can use provisioners to configure or perform next actions

=====================================================================
							  SES-33-c5
						   *****************

remote-exec
=============
terraform can connect to ec2 instance and configure it using remote-exec. basically running commands inside the server

SYNTAX:
=======
provisioner "remote-exec" { # this is for server creation code
      inline = [
 ## VSCODE
              ]
    }
provisioner "remote-exec" { # this is for server stopping code
      inline = [
 ## VSCODE
              ]
      when = destroy
    }

How to create multiple environments using terraform
===================================================
--> in terraform one of the best example enti ante.. consistent the infrastructure across the environ.. it means if u are in dev or prod or QA lo vunna we can do to create same infrastructure bcz here code is same

1. using .tfvars
2. terraform workspaces
3. individual repos

tfvars
========
it is used to override the default values of the variables
--> so in terraform keys are fixed, so then only changed the values only as per the env or DEV or PROD ... values ni control cheyatame inka
--> main advtage is code reused

Terraform Workspace
=====================
--> Env is nothing but workspace
--> if u a done any changes in provider.tf file then immediately give cmd like (terraform init -reconfigure )

-- >how to get a key in a map in terraform........... https://developer.hashicorp.com/terraform/language/functions/lookup
Syntax:
=======
lookup(<map>, <key>, <default_value>)

The Terraform lookup function retrieves a single value from a map variable (a collection of key-value pairs) given a specific key. It allows for dynamic configuration and helps maintain clean, reusable code. 



maintain different repos for different environments
================================
--> here individual ga env wise repos ni create chesukoni code rasukunte better.. bcz to over come issue 
--> but here code anedhi repeated ga avuthundhi..

roboshop-infra-dev
roboshop-infra-prod

OVER VIEW
=================================================================================
1. Tfvars
2. Workspaces
3. Different repos

first 2 methods
=============
same code for all environments, code re use --- these are adv
whatever code is written it may be accidentally applied into PROD ---> these are dis

for 3rd method
==============
uses for different repos
=====
clear isloation b/w environments, no accidental changes
code should be duplicated -> disadvantage

=====================================================================
							  SES-34-c6
						   *****************

*** Modules development ***
========
--> common code antha oka chota vunttadhi, that is called MODULES

DIS/Drawbacks 
==============
1. if there is version need to change so then, we need to update in all components ..assume like that we have 10000 components so here difficult to change for all 10000
2. there are no common standards for all the projects, means same code use cheyaru ..
3. maintenance and update is very tough

--> parameterised cheyatum ante variables laga create cheyatame...users ki chance ivvali values ni update cheyadaniki.

---> parameterised code means manaki kavalisina parameters ni send cheste code will be execute 

module advantages
=================
1. changes at single place cascade to all components using that module -> centralised approach--> also called platform engineering..
--> oka org ki rase code ni called as platform engineering..
2. we can implement industry best standards in the module, all other components are forced to use. better for governance, compliance and auditing
3. code reuse
module developers --> whoever developing module we will called as 

terraform naming convention 
===========================
srikanth_reddy_e -> for programs understand --> whichever could see for program or computer we need to use _(underscore)

srikanth-reddy-e -> for humans understand --> whichever could see for humans we need to use -(iphen)

--> for EX: https://www.terraform-best-practices.com/naming --> here see in ex as well for better understand

--> syntax is below
-------------------------
module "module-name" {

	source = ""
	mandatory-variables
}

--> terraform init anedhi provider lo emaina changes chesina and  roboshop-test folder lo vunde ec2.tf lo changes chesina we have to re run
---> instance_type ni manam control cheyali bcz if we use large t3 type we will loose many budget 
validation {
    condition     = contains(["t3.micro", "t3.small", "t3.medium"], var.instance_type)
    error_message = "Please select either t3 micro or small or medium"
  }
--> terraform-aws-module code rasetappudu we assume like max values ni parameterised chese laga vundali and default value kuda pettali
--> use chesetappudu u can see roboshop-ec2-test file vallu rasina code ni source lo refer cheyali
--> andhulo avi mandatory anni istam like ami_id and instance-type ala next output chusi manaki nachhina value tisukovadame

OVER VIEW
=================================================================================

us-east-1 -> AWS control full authority and all global services are here

Multi Cloud -> AWS, Azure, GCP --> ila multi cloud lo vundali aws down ithe gcp loki switch avvali so ala atleast 2 ayina vundali..
--> but companies cloud loki ravadaniki reason cost reduce.. but 2 service tisukovali ante adhi shocking companies kii

Module ->common code is here must provide inputs and outputs documentation. Module must provide outputs
Infra code -> provider set here, so here it needs to be pass inputs to module. Must receive outputs from module

module "module_name" {

	source = ""
	module_vars = "values"
}

=====================================================================
							  SES-35-c7
						   *****************

VPC(Virtual private cloud) ->  
=========================
acting like a virtual data center where you launch and control your resources (like EC2 instances, databases)in isolated space, with full control over IP addresses and subnets, gateways, and security settings, we are completely responsible to this.

For servers maintain 
===================
one room
power connection
network connection
AC
physical security

a subnet is a range of IP addresses within your Virtual Private Cloud (VPC) that acts as a logical subdivision for organizing and isolating your resources, for maintenance and security.  like EC2 instances, within a single Availability Zone 
Subnets -> we create partitions in the network for maintenance and security.

IP Address --> Generally it has 32 bits 

4 Octates -> here 1 octa is equals to 8 bits each(4*8) = 32 bits
255.255.255.255 --> max ip adress

IP is combination of Network + Host(server)

CIDR = Classless Inter Domain Routing
10.0.0.0/16 from here the range will be start CIDR

10.0.0.0/24 from here the range will be start for subnet 

what is difference b/w pub rt and pvt rt?
--------------------------------------------
Think of a public subnet as a shop with a front door facing the street (internet), while a private subnet is a back room that only gets deliveries through a loading dock (NAT Gateway) and has no street-facing door. 

--> Subnet which have access to IGW rt is called PUB RT
--> Subnet which don't have access to IGW is called PVT RT

 so finally formula is 
=====================
n bits -> how many numbers -> 2^n
32 bits ipv4 --> n=32 --> 2^32  GT is 4.29 billions ip lu possible
--> so ila every persons ki 4 vuntai min in this generation so to over come this issue they introduce pub and pvt 

What is NAT gateway?
----------
 NAT (Network Address Translation) Gateway is a managed service that enables resources in a private subnet to connect to the internet or other AWS services while preventing the internet from initiating a connection with those resources

EX : If we want to enable egress internet access to the private servers we can enable NAT gateway. for installation, patches, etc.

Elastic IP == Static IP
-----------------------
Designed for dynamic cloud environments, allowing you to quickly remap it from one instance to another and providing a consistent, internet-routable endpoint even if your underlying server changes

The Three Private IPv4 Ranges

--> 10.0.0.0/8: The largest block, from 10.0.0.0 to 10.255.255.255, commonly used for large enterprise networks.

172.16.0.0/12: A medium-sized range, from 172.16.0.0 to 172.31.255.255, often seen in corporate environments.

192.168.0.0/16: The most common for home networks, from 192.168.0.0 to 192.168.255.255, used by most home routers. 

NACL
------
In AWS, a Network Access Control List (NACL) is a stateless virtual firewall that controls traffic in and out of your subnets, acting as an optional security layer for your Virtual Private Cloud (VPC)

Bastion Host : it used to connect private server by using public server, once u entered the public server then if u want connect private there u must be give the private Ip address after then u could connect private server

A bastion host in AWS is a dedicated Amazon EC2 instance that acts as a secure gateway to access other instances located in private subnets


Path for creation the above statements>>> create VPC---> create IG attach to VPC --> create Route table attach to IG -->create subnet attach to RT(Route table) ----> inside subnet create server EC2 

--> subnet range will be select within the range of VPC it measn VPC range kante thakkuva select cheayali
--> 10.0.0.0/16 anedhi oka village ki assign cheste andhulo, one street ki 10.0.0.0/24 ip lu assign chesaru so street ki assign chesinavi within range of village ips


=====================================================================
							  SES-36-c8
						   *****************

VPC creation through TERRAFORM 



VPC peering
============
if we want communication between multiple VPC, we need peering. By default one vpc can't communicate with another VPC
--->A VPC peering connection helps you to facilitate the transfer of data. 

VPC has some rules:
-==================
1. VPC's should not have same CIDR
2. routes also should be available

What are the VPC should connect?
=============================
same region VPC's could be connect
diff region VPC could be connect
diff account and diff region VPC's could be connect

-->oka accout lo vunna VPC ni another account vunna VPC ni connect avvachu 
--> mainly a company while working with thrird party company so then for data sharing activity is done through this peering function

Manual Process for peering connection 
============
Accepter is default VPC ID (Accepter) vpc-084d24f93b8479e30

requester is robo-dev VPC ID (Requester) vpc-0821ce8a7258c4910 (roboshop-dev)
--> peering lo opposite side vallu kuda accept chestene aa peering function work ayyedhi.. once oka side peering connection create chesaka opposite vallaki cheppali please accept my peering connection ani
--> for accept steps are --> go to action --> click on accept --> this is done by same region lo 
--> region lo ithe vallali chepali accept chei ani

Village-1 numchi Village-2 ki vellali ante manki road avasarum 

source = village-1
destination = Village-2

--> so village-1 velli village-2 ni connect avvali anukunte dhani routes lo village 2 destination (CIDR) ivvali and peering ni select cheesukovai 
vilage-2 kuda village-1 ni connect avvali so village-2 rotes lo destination icchi (CIDR) ivvali village-1 dhi



=====================================================================
							  SES-37-c9
						   *****************
--> for detailed process for Peering connection 
--> VPC full structure draw in VPC dig page doc

--> ekkada problem vachhina adhi rt network lone so we need to troubleshoot in that only 
→ By default there is no connection in b/w 2 VPC’s, bcz those are isolated 
-->manual process there in session 37 refer that notes 

--> basically peer anedhi option not a mandatory,
var.is_peering_required ? 1 : 0 ( ila condition set chesi user ki ivvali valla istum) 
data.aws_vpc.default.id ( every aws lo default vpc vunttadhi dhani manam fetch chestunam) 

--> upto here peering connection done through terraform 
--> then mana code antha mana local windows lo vundhi but git lo vunde dhani kadha refer cheyali, real time lo git loki push chestaru module developers 
source = "git::https://github.com/SrikanthErugula/terraform-AWS-VPC-module.git?ref=main" ( so ila specific ga main branch ivvachu, module vere brach lo vunde brach name  change chesukovachu ) 

--> module lo chages cheste if u want latest module then u give cmd is 
terraform init upgrade 

--> for every rea time lo projects we need VPC creation bcz security

Basically modules are 3 types
=============================== 
1. Customised modules -> we develop, maintain. full control --> top MNC will go this way
2. Open source modules -> 3rd party developed use doc and community links tho--> no need to develop, directly use it. we don't have full control --> form internet or google modules  ---> small companies will go this way 

3. direct resource creation for small cases

---> interview lo memu both use chese valla once upon time lo past years ago then we will get some error client not satisfied with that so but now we are build inhouse modules 

--> ippati varaku chesina codes lo same eg use chesam but real time frontend ki pvt ki db ki vere vunttadhi, now we are go that way below are the naming conversion 
roboshop-dev-catalogue  --> ila mana istum project wise we can 
roboshop-dev-mongodb

SSM PARAMETER
==========
--> SSM  lo secrets and non secrets both vuntai anisble lo pwd lo kosam secrets use chesam ikkada non secrets use chestam like type sting istam anthe 

--> In real time lo vpc ki vere team and sg ki vere team 
--> parameters create chese vallu doc lo mention chestaru like Alanti parameter use chestunaru ani and dhani path


Topics: covered in this session 
========
VPC Module and peer connection done  through terraform
Roboshop infra creation 
SSM parameter store


=====================================================================
							  SES-38-c10
						   *****************

--> ingress anedhi sg lo big process and we need to get approval higher magnt 
--> egress is same for all and it was open no restrictions 
--> Generally we have 2 tyoes of infra 
1. Project Infra -> One time infra creation (EX state or central govt, companies ki land or availability handover chestundhi sothen company vallu akkada build chestar)
2. Application Infra -> frequent changes will have, then we need to changes the infra
--> first we need to set project infra like load balancer or vpc then after app infra like ec2 instance depends upon traffic 
--> sg grp if it has been done, there is no re create groups, changes will have inside infra like rules 

BASTION ( JUMP SERVER) 
==========
--> pvt lo vunde sg or chages chudalante we need to connect BASTION .... see in dig in VPC page 
--> Bastion is nothing but like as ec2 server, it used to jump into pvt server or subnets to find which have inside data in that 
--> bastion create avvalante is depends on sg id
--> bastion sg id ni refer cheyalante sg anedhi ssm parameter lo pettali dhani tisukoni bastion create avuthundhi 
StringList == Separate strings using commas(,).

Srikanth, Reddy, Erugula, E --> for humans understand list

["siva","kumar","reddy","m"] ---> for computer understand list

convert list to string in terraform we have 2 functions like as below 
join function and split function

join -> join the elements in list as single string with separator by using comma(,)

value = join("," , module.vpc.public_subnet_ids) --> so here 2 Az's select chesam so we got 2 subnets ids like as below

subnet-0b74d14411866ada1,subnet-01c3ab188edc1bb04 --> this is output for above cmd 
--> this is string but seperator is comma

LOAD Balancer
=============
--> so 1 request will come load balancer check the status
load balancer
rules
target group
health check
instance
listener -> frontend load balancer(public) 80/443, backend load balancer(private) 8080

EX:
Rule -> if frontend work is there then, assign to frontend team or else if backend work is there then assign to backend team 
Target group -> Team
Health check -> availability check
Instance -> Team member

OVER VIEW
=================
SSM parameter lo VPC ID , Subnets IDS presented, other modules like sg or bastion and more ... those are all used inside ssm parameter data
--> create chesetappudu ssm parameters and use purpose data sources 
--> Bastion is nothing but like as ec2 server, it used to jump into pvt server or subnets to find which have inside data in that 

Load Balancer == Manager/Lead/DM

Listener = Whom we are listening to. Delivery Manager ane vadu BA vadu emi chepte adhi vinali . normal Manager ane vadu -> DM emi chepte adi  Lead ane vadu Manager emi chepte adhi vinali  
---> so finally structure is BA --> DM --> Manager -->Lead --> team member needs to do


























